import React, { useState, useRef, useEffect } from 'react';
import { View, FlatList, TextInput, KeyboardAvoidingView, Platform, Keyboard, Alert, TouchableOpacity } from 'react-native';
import { Text, ActivityIndicator, IconButton, Avatar, Chip } from 'react-native-paper';
import { useRouter, Stack } from 'expo-router';
import * as Speech from 'expo-speech';
import { Audio } from 'expo-av';

// ‚≠ê FIX QUAN TR·ªåNG ‚Äì KH√îNG D√ôNG API B·ªä DEPRECATED
import * as FileSystem from 'expo-file-system/legacy';

import { auth, db } from '../firebaseConfig';
import { addDoc, collection, query, orderBy, limit, getDocs } from 'firebase/firestore';

import { styles } from '../styles/chatbot.styles';

const GEMINI_API_KEY = process.env.EXPO_PUBLIC_GEMINI_API_KEY;

export default function ChatbotScreen() {
  const router = useRouter();
  const [messages, setMessages] = useState([
    { id: '1', text: 'Ch√†o b·∫°n! T√¥i l√† tr·ª£ l√Ω m√¥i tr∆∞·ªùng AI. B·∫°n c·∫ßn gi√∫p g√¨ kh√¥ng?', sender: 'bot', timestamp: Date.now() }
  ]);
  const [inputText, setInputText] = useState('');
  const [loading, setLoading] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [recording, setRecording] = useState(null);
  const flatListRef = useRef(null);

  useEffect(() => {
    const loadHistory = async () => {
      const user = auth.currentUser;
      if (!user) return;

      try {
        const q = query(collection(db, `users/${user.uid}/chatHistory`), orderBy('timestamp', 'desc'), limit(15));
        const snapshot = await getDocs(q);
        const history = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() })).reverse();

        if (history.length > 0) {
          // Gh√©p l·ªãch s·ª≠ v√†o nh∆∞ng gi·ªØ c√¢u ch√†o ban ƒë·∫ßu
          setMessages(prev => [...history, ...prev.slice(1)]);
        }
      } catch (error) {
        console.log("L·ªói t·∫£i l·ªãch s·ª≠ chat:", error);
      }
    };

    loadHistory();

    return () => {
      Speech.stop();
      if (recording) recording.stopAndUnloadAsync();
    };
  }, []);

  // ------------------- RECORDING -------------------
  const startRecording = async () => {
    try {
      const perm = await Audio.requestPermissionsAsync();
      if (perm.status !== 'granted') {
        Alert.alert("L·ªói", "C·∫ßn quy·ªÅn truy c·∫≠p Microphone.");
        return;
      }

      await Audio.setAudioModeAsync({ allowsRecordingIOS: true, playsInSilentModeIOS: true });

      const recordingOptions = {
        android: {
          extension: '.m4a',
          outputFormat: Audio.AndroidOutputFormat.MPEG_4,
          audioEncoder: Audio.AndroidAudioEncoder.AAC,
          sampleRate: 44100,
          numberOfChannels: 2,
          bitRate: 128000,
        },
        ios: {
          extension: '.m4a',
          audioQuality: Audio.IOSAudioQuality.HIGH,
          sampleRate: 44100,
          numberOfChannels: 2,
          bitRate: 128000,
        },
      };

      const { recording } = await Audio.Recording.createAsync(recordingOptions);
      setRecording(recording);
    } catch (err) {
      console.error("L·ªói ghi √¢m:", err);
      Alert.alert('L·ªói', 'Kh√¥ng th·ªÉ ghi √¢m.');
    }
  };

  const stopRecording = async () => {
    if (!recording) return;
    const rec = recording;
    setRecording(null);

    await rec.stopAndUnloadAsync();
    const uri = rec.getURI();

    if (uri) handleSendAudio(uri);
  };

  // ------------------- SEND AUDIO TO GEMINI -------------------
  const handleSendAudio = async (uri) => {
    const user = auth.currentUser;

    const userMsg = {
      id: Date.now().toString(),
      text: "üé§ (ƒêang g·ª≠i gi·ªçng n√≥i...)",
      sender: 'user',
      timestamp: Date.now(),
      isAudio: true
    };

    setMessages(prev => [...prev, userMsg]);
    setLoading(true);

    try {
      // ‚≠ê ƒê√É FIX API readAsStringAsync
      const base64Audio = await FileSystem.readAsStringAsync(uri, { encoding: 'base64' });

      const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${GEMINI_API_KEY}`,
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            contents: [{
              parts: [
                { text: "H√£y nghe ƒëo·∫°n √¢m thanh v√† tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn v√† th√¢n thi·ªán." },
                { inline_data: { mime_type: "audio/m4a", data: base64Audio } }
              ]
            }]
          })
        }
      );

      const data = await response.json();
      if (data.error) throw new Error(data.error.message);

      const botText = data.candidates?.[0]?.content?.parts?.[0]?.text || "T√¥i kh√¥ng nghe r√µ, b·∫°n n√≥i l·∫°i nh√©?";
      const botMsg = { id: Date.now().toString(), text: botText, sender: 'bot', timestamp: Date.now() };

      setMessages(prev => [...prev, botMsg]);
      if (user) addDoc(collection(db, `users/${user.uid}/chatHistory`), botMsg);

      speakText(botText);

    } catch (error) {
      console.error("L·ªói x·ª≠ l√Ω audio:", error);
      Alert.alert("L·ªói AI", error.message);
    } finally {
      setLoading(false);
    }
  };

  // ------------------- SEND TEXT TO GEMINI -------------------
  const sendMessage = async (customText) => {
    const textToSend = customText || inputText;
    if (!textToSend.trim()) return;

    const user = auth.currentUser;
    const userMsg = { id: Date.now().toString(), text: textToSend, sender: 'user', timestamp: Date.now() };

    setMessages(prev => [...prev, userMsg]);
    setInputText('');
    Keyboard.dismiss();

    Speech.stop();
    setIsSpeaking(false);

    if (user) addDoc(collection(db, `users/${user.uid}/chatHistory`), userMsg);

    setLoading(true);

    try {
      const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${GEMINI_API_KEY}`,
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            contents: [{
              parts: [{ text: `B·∫°n l√† chuy√™n gia m√¥i tr∆∞·ªùng. Tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† s√∫c t√≠ch: ${textToSend}` }]
            }]
          })
        }
      );

      const data = await response.json();
      if (data.error) throw new Error(data.error.message);

      const botText = data.candidates?.[0]?.content?.parts?.[0]?.text || "Kh√¥ng th·ªÉ k·∫øt n·ªëi AI.";
      const botMsg = { id: Date.now().toString(), text: botText, sender: 'bot', timestamp: Date.now() };

      setMessages(prev => [...prev, botMsg]);
      if (user) addDoc(collection(db, `users/${user.uid}/chatHistory`), botMsg);
      speakText(botText);

    } catch (error) {
      console.error("L·ªói chat text:", error);
      Alert.alert("L·ªói", "AI kh√¥ng ph·∫£n h·ªìi.");
    } finally {
      setLoading(false);
    }
  };

  // ------------------- TEXT TO SPEECH -------------------
  const speakText = (text) => {
    setIsSpeaking(true);
    Speech.speak(text, {
      language: 'vi-VN',
      rate: 0.92,
      onDone: () => setIsSpeaking(false),
      onError: () => setIsSpeaking(false)
    });
  };

  const stopSpeaking = () => {
    Speech.stop();
    setIsSpeaking(false);
  };

  useEffect(() => {
    setTimeout(() => {
      flatListRef.current?.scrollToEnd({ animated: true });
    }, 200);
  }, [messages, loading]);

  // ------------------- RENDER MESSAGES -------------------
  const renderMessage = ({ item }) => {
    const isUser = item.sender === 'user';

    return (
      <View style={[styles.msgContainer, isUser ? styles.msgRight : styles.msgLeft]}>
        {!isUser && <Avatar.Icon size={32} icon="leaf" style={styles.botAvatar} color="#0E4626" />}
        <View style={isUser ? styles.bubbleRight : styles.bubbleLeft}>
          <Text style={isUser ? styles.textRight : styles.textLeft}>{item.text}</Text>
        </View>
      </View>
    );
  };

  // ------------------- UI -------------------
  return (
    <View style={styles.container}>
      <Stack.Screen options={{ headerShown: false }} />

      <View style={styles.headerBar}>
        <IconButton icon="arrow-left" onPress={() => router.back()} iconColor="#0E4626" size={26} style={styles.backBtn} />
        <Text style={styles.headerTitle}>Tr·ª£ l√Ω AI</Text>

        {isSpeaking && (
          <IconButton icon="volume-off" onPress={stopSpeaking} iconColor="#D32F2F" size={24} />
        )}
      </View>

      <FlatList
        ref={flatListRef}
        data={messages}
        keyExtractor={(item) => item.id}
        renderItem={renderMessage}
        contentContainerStyle={styles.chatContent}
        style={{ flex: 1 }}
        ListFooterComponent={
          loading ? (
            <ActivityIndicator size="small" color="#0E4626" style={{ marginTop: 10 }} />
          ) : null
        }
      />

      {/* Quick Chips */}
      <View style={{ maxHeight: 50 }}>
        <FlatList
          horizontal
          showsHorizontalScrollIndicator={false}
          data={["C√°ch t√°i ch·∫ø pin?", "Ph√¢n lo·∫°i r√°c nh·ª±a?", "M·∫πo ti·∫øt ki·ªám ƒëi·ªán"]}
          contentContainerStyle={styles.chipContainer}
          renderItem={({ item }) => (
            <Chip
              onPress={() => sendMessage(item)}
              style={styles.chipItem}
              textStyle={styles.chipText}
              icon="sprout"
            >
              {item}
            </Chip>
          )}
        />
      </View>

      <KeyboardAvoidingView behavior={Platform.OS === 'ios' ? 'padding' : undefined}>
        {recording && <Text style={styles.recordingText}>ƒêang nghe... (Th·∫£ tay ƒë·ªÉ g·ª≠i)</Text>}

        <View style={styles.inputWrapper}>
          <TouchableOpacity
            onPressIn={startRecording}
            onPressOut={stopRecording}
            style={[styles.micBtn, recording ? styles.micBtnActive : null]}
          >
            <IconButton
              icon="microphone"
              iconColor={recording ? '#D32F2F' : '#0E4626'}
              size={24}
              style={{ margin: 0 }}
            />
          </TouchableOpacity>

          <TextInput
            style={styles.textInput}
            placeholder="Nh·∫≠p c√¢u h·ªèi..."
            value={inputText}
            onChangeText={setInputText}
            onSubmitEditing={() => sendMessage()}
            editable={!recording}
            placeholderTextColor="#999"
            multiline
          />

          <TouchableOpacity
            style={[styles.sendBtn, { opacity: (!inputText.trim() && !loading) ? 0.5 : 1 }]}
            onPress={() => sendMessage()}
            disabled={loading || !inputText.trim()}
          >
            <IconButton icon="send" iconColor="#fff" size={20} style={{ margin: 0 }} />
          </TouchableOpacity>
        </View>
      </KeyboardAvoidingView>
    </View>
  );
}
